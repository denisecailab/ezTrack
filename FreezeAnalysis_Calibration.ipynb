{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "The following code was designed to be used in conjunction with FreezeAnalysis_Individual.ipynb and FreezeAnalysis_BatchProcess.ipynb in order to set the motion threshold parameter.  By examining basal fluctuation in pixel intensities in a video where no animal is present, it is possible to set a threshold for detecting pixel change values that are attributable to animal motion, as oppposed to low-level fluctuation that occurs with no animal present.  \n",
    "\n",
    "***Videos must NOT contain animals for this step to work properly***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Load Necessary Packages\n",
    "The following code loads neccessary packages and need not be changed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import FreezeAnalysis_Functions as fz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. User Sets Directory and File Information\n",
    "\n",
    "`dpath` : The directory path of the folder containing the video to be processed. Note that if you are using a Windows path with backslashes, place an ‘r’ in front of the directory path to avoid an error (e.g., r’\\Users\\DeniseCaiLab\\Videos’).\n",
    "\n",
    "`file` : The filename of the video, including the file extension.\n",
    "\n",
    "`cal_frms` : The number of frames in the video to calibrate based upon.  If the video is 10 seconds long and was shot at 30 frames per second, the user might set this to 300.  If the user is unsure of the frame rate, this information will be output by ezTrack when Cell 3 is run.  Note that for longer videos, it is not necessary to calibrate based upon the total number of frames in the video.\n",
    "\n",
    "`dsmpl` : The amount to down-sample each frame.  If processing is going slow, down-sampling can help. A value of 1 indicates no down-sampling, while a value of 0.25 indicates that the frame will be down-sampled to ¼ the original size.  Note that if the user chooses to down-sample in the calibration step, this same down-sampling factor should be used for processing behavioral videos and vice versa.\n",
    "\n",
    "`stretch` : Allows the user to alter the aspect ratio of the presented output.  This is useful when videos have irregular dimensions and are difficult to see (e.g., an aspect ratio of 1:100).  The width/height will be scaled by the factor provided. Note that this only affects the appearance of visualizations and does not modify the video or the interpretation of the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dict = {\n",
    "    'dpath'    : \"./PracticeVideos\", # fix me\n",
    "    'file'     : \"LocationTracking_Clip.mp4\", # fix me\n",
    "    'cal_frms' : 300,\n",
    "    'dsmpl'    : 1,\n",
    "    'stretch'  : dict(width = 1, height = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Load Video Information.  Display First Frame\n",
    "The following code loads pertinent video information and displays the first frame of the video.  If the size of the image is too small/large, alter the first line of code.  100 is the standard size.  200 will produce an image 2x the size, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "\n",
    "img_crp, video_dict = fz.LoadAndCrop(video_dict)\n",
    "img_crp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Calibrate Video \n",
    "The following code will select a random set of pixels (10k, by default) and looks at how their grayscale intensity changes across the specified length of the video.  By looking at the distribution of frame-by-frame change values, a threshold can then be set for determining what changes are likely attributable to the animal moving versus random fluctuation.  Currently, a suggested cutoff of twice the 99.99 percentile is displayed.   A plot of grayscale change values is also provided.  Zooming tools adjacent to the plot can be used to more closely examine low-frequency changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "\n",
    "hist = fz.Calibrate(video_dict, cal_pix=10000, SIGMA=1)\n",
    "hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
